{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98941bae",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Primeiro Trabalho Computacional. Regressão Linear na qualidade de cerveja. \n",
    "\n",
    "\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Está fornecido um arquivo csv (valores separados por vírgula) contendo características químicas de amostra de cerveja, e sua qualidade avaliada por especialistas, em uma escala de 6 a 10. Seu objetivo é avaliar um sistema de regressão linear sobre este problema. \n",
    "\n",
    "Os módulos, classes e definições contidas aqui devem ser vistas como sugestão. Desde que você use Python, apresente seu trabalho como um notebook e responda às perguntas, os requisitos estão satisfeitos. Eu também não tenho objeções ao uso de código encontrado na internet ou via chatGPT, mas use-os por sua conta e risco. \n",
    "\n",
    "## 2. Classes e Métodos\n",
    "\n",
    "Com estes módulos, classes e métodos que se seguem, o laço principal de treinamento fica muito simples. Lembre-se de ativar o d2l antes de invocar o notebook. Estou usando também o módulo sklearn para a divisão do arquivo em treinamento e validação. É preciso instalá-lo com `pip install sklearn` no terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b6d94b",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 19:52:17.356970: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-27 19:52:17.385228: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-27 19:52:17.385806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-27 19:52:17.944059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from d2l import tensorflow as d2l\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d6f006-3fc5-4fc4-88d8-1b3789040c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(d2l.Module):  #@save\n",
    "    \"\"\"The linear regression model implemented with high-level APIs.\"\"\"\n",
    "    \"\"\"Do d2l\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        initializer = tf.initializers.RandomNormal(stddev=0.01)\n",
    "        self.net = tf.keras.layers.Dense(1, kernel_initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ddaa60-e4c6-4deb-85e5-ec471af47e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionData(d2l.DataModule):  #@save\n",
    "    \"\"\"Data for linear regression.\"\"\"\n",
    "    def __init__(self, nInputs,data,num_train=5197, num_val=1300,\n",
    "                 batch_size=32):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.X=data[:,0:nInputs]\n",
    "        self.y=data[:,nInputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5075ad79-5f7f-497c-8061-043a2a102f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.DataModule)  #@save\n",
    "def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "    tensors = tuple(a[indices] for a in tensors)\n",
    "    shuffle_buffer = tensors[0].shape[0] if train else 1\n",
    "    return tf.data.Dataset.from_tensor_slices(tensors).shuffle(\n",
    "        buffer_size=shuffle_buffer).batch(self.batch_size)\n",
    "\n",
    "@d2l.add_to_class(LinearRegressionData)  #@save\n",
    "def get_dataloader(self, train):\n",
    "    i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "    return self.get_tensorloader((self.X, self.y), train, i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea90d84-432d-4c1b-8386-d16b100db074",
   "metadata": {},
   "source": [
    "## 3.  Leitura do Arquivo e Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd99f710",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "Existem 7 variáveis de entrada e 1 alvo (Quality_Score). Há 25157 exemplos, e eles não são equilibrados (não existe a mesmo quantidade para cada nível de qualidade). \n",
    "| Fermentation_Time | Temperature      | pH_Level         | Gravity          | Alcohol_Content  | Bitterness | Color | Quality_Score    |\n",
    "|-------------------|------------------|------------------|------------------|------------------|------------|-------|---|\n",
    "| 16                | 24.2042508570699 | 5.28984544760956 | 1.0395041267302  | 5.37084215955344 | 20         | 5     | 8 |\n",
    "| 13                | 18.0867629472595 | 5.27564338275619 | 1.05981895169872 | 5.09605308279763 | 36         | 14    | 7 |\n",
    "| 12                | 15.5393326691165 | 4.77801562324598 | 1.03747570954872 | 4.82473712095918 | 30         | 10    | 8 |\n",
    "| 17                | 16.4184891039432 | 5.34526058554619 | 1.05243142516949 | 5.509243080798   | 48         | 18    | 9 |\n",
    "| 18                | 19.1449076543385 | 4.86185374113861 | 1.05429611494823 | 5.13362468426324 | 57         | 13    | 7 |\n",
    "| 10                | 17.4246143933758 | 5.29178662190806 | 1.0646620426822  | 4.85917102161423 | 45         | 9     | 8 |\n",
    "| ...               | ...              | ...              | ...              | ...              | ...        | ...   | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da317ced-bf0f-4feb-a9da-770467f4183f",
   "metadata": {},
   "source": [
    "Você deve ainda usar a função `train_test_split` (o outra) para separar estes arquivos em treinamento e validação. Sugiro 20% para a validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec2ea74-1584-43b5-867f-4f85302357cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data, val_data \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      2\u001b[0m train_data\u001b[38;5;241m.\u001b[39mshape, val_data\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2)\n",
    "train_data.shape, val_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196d849",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "Finalmente, lembre-se que a função `pd.read_csv` cria um dataframe, não uma matriz. Verifique como transformar em uma matriz, que deve conter todos os exemplos de treinamento e em seguida todos os exemplos de validação. Sua dimensão final será 25157 por 8 (incluindo a variável alvo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc60b3-a45f-4131-9beb-c064fefcedd9",
   "metadata": {},
   "source": [
    "## 4. Métodos para treinamento\n",
    "\n",
    "Estes métodos definem como se dá o passo à frente (processamento da rede), qual a função de custo e otimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49248d-8639-4afb-9879-03ac2f256404",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(LinearRegression)  #@save\n",
    "def forward(self, X):\n",
    "    return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5f17e-4b41-448d-a2a9-1f0ce4d169e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(LinearRegression)  #@save\n",
    "def loss(self, y_hat, y):\n",
    "    fn = tf.keras.losses.MeanSquaredError()\n",
    "    return fn(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633adae-8065-49ea-ab50-ceb857fb33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(LinearRegression)  #@save\n",
    "def configure_optimizers(self):\n",
    "    return tf.keras.optimizers.SGD(self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98368fa-acbb-44da-a18a-aaecf2a19f8f",
   "metadata": {},
   "source": [
    "### 4.1. Treinamento\n",
    "\n",
    "Com esses passos, o laço de treinamento é bem simples. Veja o exemplo visto em sala. \n",
    "ATENÇÃO: Os dados têm variância (escala) desigual. Como nada limita a saída do modelo de regressão, uma taxa de aprendizado alta pode levar à divergência. Se o gráfico do erro fica em branco ou o treinamento leva tempo demais, este é provavelmente o caso. Experimente diferentes valores de taxa, em diferentes ordens de grandeza, para solucionar isso (10^-4, 10^-3, 10^-2, 10^-1...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f086cf-4d4b-4e1c-bb20-24cc0a399683",
   "metadata": {},
   "source": [
    "## 5. Avaliações e análise\n",
    "\n",
    "Terminado o treinamento, houve (espera-se) uma minimização do erro quadrático médio. Mas outras medidas de desempenho podem ser usadas. \n",
    "\n",
    "Para avaliar o modelo, pode ser útil a seguinte função: \n",
    "\n",
    "``prediction=model.call(inputs)``\n",
    "\n",
    "Supondo que você instanciou seu modelo como \"model\". Para fazer operações (cálculo de médias e erros), pode ser necessário mudar (reshape) algum tensor. Lembre-se de usar os dados de VALIDAÇÃO. Uma média de vários treinamentos com condiçoes iniciais (e partições da base dados) diferentes nos dá um resultado mais confiável. \n",
    "\n",
    "### 5.1. Erro absoluto médio e Preditor Trivial\n",
    "\n",
    "Qual o erro absoluto médio do seu preditor? Como a categoria é dada por inteiros de 6 a 10, esperamos, no mínimo, um erro menor do que 1, ou o sistema frequentemente erraria por mais de uma categoria. \n",
    "\n",
    "Por vezes queremos saber se, depois de todo este trabalho temos algo superior a um preditor trivial ou ingênuo. O preditor trivial atribui como saída a média da função que se quer prever. \n",
    "\n",
    "Compare os erros absolutos médios. O seu regressor é melhor do que uma simples média da saída?\n",
    "\n",
    "__Atenção__: Este problema é não-linear, e fizemos pouco pré-processamento com os dados. Não se espera um bom desempenho com este primeiro modelo simples. Ele deve, no entanto, ser melhor que o preditor trivial. \n",
    "\n",
    "### 5.2. Classificação por arredondamento\n",
    "\n",
    "Como a classificação é um índice inteiro, podemos pensar neste caso como um problema de classificação em 5 classes, e não de regressão. Veremos ferramentas mais indicadas para esta classe de problemas, mas uma solução trivial seria arredondar a saída do preditor e verificar quantas classes acertamos. \n",
    "\n",
    "Compare a taxa de acerto (vamos chamar isso acurácia mais à frente) contra o preditor-classificador trivial. Um preditor aleatório (que atribui um número de 6 a 10 aleatoriamente) deveria ter uma taxa de acerto de 20%.\n",
    "\n",
    "__Atenção__: de novo, você deve estar acima do preditor trivial, e acima dos 20%. \n",
    "\n",
    "### 5.3. Correlação\n",
    "\n",
    "Outra medida interessante para saber o quanto nosso preditor absorveu a informação contida no arquivo de dados é a __correlação__ entre saída desejada e obtida. Este é um número de -1 a 1, -1 indicando uma relação determinística negativa (quando a saída do preditor é baixa, o especialista deu nota alta e vice_versa), 0 é ausência de correlação (a saída de um não nos permite dizer nada sobre o outro) e +1 significa que o preditor substitui o especialista sem qualquer erro. Gostaríamos, é claro, de um valor próximo a 1. Observe que o preditor aleatório e também o trivial têm correlação zero com a saída desejada. \n",
    "\n",
    "### 5.4. Melhoramentos (extra)\n",
    "\n",
    "Não se espera mesmo um bom desempenho neste caso, mas algumas coisas podem ajudar. Não são requisitos para o trabalho, mas serão considerados pontos extra. \n",
    "\n",
    "* Variações no número de épocas, tamanho do \"minibatch\", taxas de aprendizado.\n",
    "* Normalização das entradas (para que tenham média zero e desvio-padrão 1).\n",
    "* (mais difícil) Uma análise estatística que elimine variáveis pouco informativas, ou proponha uma combinação polinomial mais informativa de algumas variáveis.\n",
    "\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
